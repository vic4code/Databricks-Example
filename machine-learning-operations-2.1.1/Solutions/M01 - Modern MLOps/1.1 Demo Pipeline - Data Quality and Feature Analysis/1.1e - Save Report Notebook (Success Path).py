# Databricks notebook source
# MAGIC %md
# MAGIC
# MAGIC <div style="text-align: center; line-height: 0; padding-top: 9px;">
# MAGIC   <img src="https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png" alt="Databricks Learning">
# MAGIC </div>
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC # Task 4 - Save Report
# MAGIC This task compiles a comprehensive report summarizing the data quality assessment, feature importance analysis, and unusual pattern detection. This final report provides valuable insights into the data, serving as a foundation for the machine learning pipeline.
# MAGIC
# MAGIC **Objectives:**
# MAGIC
# MAGIC - Compile results from previous tasks into a single, coherent report.
# MAGIC - Save the report for future reference and analysis.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Requirements
# MAGIC
# MAGIC Please review the following requirements before starting the lesson:
# MAGIC
# MAGIC * To run this notebook, you need to use one of the following Databricks runtime(s): **15.4.x-cpu-ml-scala2.12**

# COMMAND ----------

# MAGIC %md
# MAGIC ## Classroom Setup
# MAGIC
# MAGIC Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:

# COMMAND ----------

# MAGIC %run ../../Includes/Classroom-Setup-1.1demo

# COMMAND ----------

# MAGIC %md
# MAGIC **Other Conventions:**
# MAGIC
# MAGIC Throughout this lab, we'll refer to the object DA. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:

# COMMAND ----------

print(f"Username:          {DA.username}")
print(f"Catalog Name:      {DA.catalog_name}")
print(f"Schema Name:       {DA.schema_name}")
print(f"Working Directory: {DA.paths.working_dir}")
print(f"User DB Location:  {DA.paths.datasets}")

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ##Task Outline
# MAGIC In this task, we will:
# MAGIC
# MAGIC - Load and compile individual reports generated from previous tasks (Data Quality, Feature Importance, and Unusual Patterns).
# MAGIC - Generate a comprehensive final report.
# MAGIC - Save the report to a specified location for future reference.

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ###Step 1: Load Individual Reports
# MAGIC In this step, we load the data quality report, feature importance report, and unusual patterns report generated by previous tasks. These files are saved in the DBFS (Databricks File System) and will be read into the notebook.

# COMMAND ----------

# Define paths for each report
data_quality_report_path = "./data_quality_report.txt"
feature_importance_report_path = "./feature_engineered_output_with_visualization_data.json"
unusual_patterns_report_path = "./unusual_patterns_report.txt"

# Import pandas
import pandas as pd

# Load Data Quality Report
print("Loading Data Quality Report...")
with open(data_quality_report_path, "r") as f:
    data_quality_report = f.read()

print("Data Quality Report Loaded")

# Load Feature Importance Report
print("\nLoading Feature Importance Report...")
feature_importance_report = pd.read_json(feature_importance_report_path)
print("Feature Importance Report Loaded")

# Load Unusual Patterns Report
print("\nLoading Unusual Patterns Report...")
with open(unusual_patterns_report_path, "r") as f:
    unusual_patterns_report = f.read()

print("Unusual Patterns Report Loaded")

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ### Step 2: Compile the Final Report
# MAGIC In this step, we will combine all the individual reports into a single, cohesive document. This final report provides a comprehensive overview of the data quality, feature importance, and unusual pattern detection results.

# COMMAND ----------

# Define the path for the final report
final_report_path = "../final_report.txt"

print("Compiling Final Report...")

with open(final_report_path, "w") as f:
    # Write Data Quality Report
    f.write("Data Quality Report\n")
    f.write("===================\n")
    f.write(data_quality_report + "\n\n")
    
    # Write Feature Importance Report
    f.write("Feature Importance Report\n")
    f.write("=========================\n")
    f.write(feature_importance_report.to_string(index=False) + "\n\n")
    
    # Write Unusual Patterns Report
    f.write("Unusual Patterns Report\n")
    f.write("=======================\n")
    f.write(unusual_patterns_report)

print("Final report compiled and saved to:", final_report_path)

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ###Step 3: Display Final Report Summary
# MAGIC For a quick overview, we display summaries of each section in the notebook output, which provides insights without needing to open the full report file.

# COMMAND ----------

print("=== Data Quality Report ===")
print(data_quality_report)

print("\n=== Top Features by Importance ===")
print(feature_importance_report.head())

print("\n=== Unusual Patterns Report ===")
print(unusual_patterns_report)

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ###Step 4: Save Report to Specified Location
# MAGIC Ensure the final report is saved in the specified location in DBFS for future access and reference.

# COMMAND ----------

# Confirm the final report path
print(f"Final report successfully saved at: {final_report_path}")

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ##Conclusion
# MAGIC In this notebook, we:
# MAGIC
# MAGIC - Loaded individual reports from data quality assessment, feature importance analysis, and unusual pattern detection.
# MAGIC - Compiled these reports into a single comprehensive document.
# MAGIC - Saved the final report to DBFS, where it can be accessed as needed.
# MAGIC
# MAGIC This final report provides a foundational analysis of the data, which will inform future machine learning tasks. With this step completed, the data is now validated and insights documented, allowing for a robust machine learning pipeline setup.

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC &copy; 2025 Databricks, Inc. All rights reserved.<br/>
# MAGIC Apache, Apache Spark, Spark and the Spark logo are trademarks of the 
# MAGIC <a href="https://www.apache.org/">Apache Software Foundation</a>.<br/>
# MAGIC <br/><a href="https://databricks.com/privacy-policy">Privacy Policy</a> | 
# MAGIC <a href="https://databricks.com/terms-of-use">Terms of Use</a> | 
# MAGIC <a href="https://help.databricks.com/">Support</a>